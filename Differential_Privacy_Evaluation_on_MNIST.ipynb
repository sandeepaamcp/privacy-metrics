{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvzzq2VyAOWkt241IGvfxW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepaamcp/privacy-metrics/blob/main/Differential_Privacy_Evaluation_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Differential Privacy evalution for ML models\n",
        "\n",
        "This notebook uses Opacus library for adding noise to the gradients via Differential Privacy (DP). First, required libraries are installed. Then, the configurations for DP is stored as Args. Next, dataset and NN architectures are made. The plain model is sent to a privacy engine, which will implement DP."
      ],
      "metadata": {
        "id": "BpehmwfG433B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install libraries"
      ],
      "metadata": {
        "id": "dS0U75DQ41eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus --quiet"
      ],
      "metadata": {
        "id": "h8fx3wRpoYhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085d4813-8954-4670-9ef4-14240fb85e1e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SazhsTGiPB-",
        "outputId": "15a54740-4579-453d-95ee-17b98e7e9eaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from opacus import PrivacyEngine\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n"
      ],
      "metadata": {
        "id": "dFVBf9Fk8evf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precomputed characteristics of the MNIST dataset\n",
        "MNIST_MEAN = 0.1307\n",
        "MNIST_STD = 0.3081\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "0sQoqWot8htj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    epochs=15 # number of epochs\n",
        "    n_runs=1 # allow multiple independent run so you can take average of accuracy\n",
        "    lr=0.25 # learning rate\n",
        "    sigma=1.3 # noise multiplier in the DP optimizer, necessary to set to non-zero for DP\n",
        "    max_per_sample_grad_norm=1.5  # clipping norm to guarantee the sensitivity of gradients; necessary to set to non-infinity for DP\n",
        "    delta=1e-5 # delta in (epsilon, delta)-DP, need to be smaller than 1/sample size\n",
        "    data_root=\"./data\"\n",
        "    disable_dp=False\n",
        "    batch_size=64\n",
        "    test_batch_size=1024\n",
        "    secure_rng=False\n",
        "    epsilon=1\n",
        "    # if True, then this is training with no clipping (hence not DP);\n",
        "    # if False, and if sigma not zero, then DP; else, this is non-DP training with clipping\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "pH_0VDerz68u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 8, 2, padding=3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 4, 2)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x of shape [B, 1, 28, 28]\n",
        "        x = F.relu(self.conv1(x))  # -> [B, 16, 14, 14]\n",
        "        x = F.max_pool2d(x, 2, 1)  # -> [B, 16, 13, 13]\n",
        "        x = F.relu(self.conv2(x))  # -> [B, 32, 5, 5]\n",
        "        x = F.max_pool2d(x, 2, 1)  # -> [B, 32, 4, 4]\n",
        "        x = x.view(-1, 32 * 4 * 4)  # -> [B, 512]\n",
        "        x = F.relu(self.fc1(x))  # -> [B, 32]\n",
        "        x = self.fc2(x)  # -> [B, 10]\n",
        "        return x\n",
        "\n",
        "    def name(self):\n",
        "        return \"SampleConvNet\""
      ],
      "metadata": {
        "id": "ATlF4I7Q8otx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, train_loader, optimizer, privacy_engine, epoch):\n",
        "    # sample function to get length of the dataset\n",
        "    num_samples = 0\n",
        "    for batch in train_loader:\n",
        "        num_samples += batch[0].shape[0]\n",
        "\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "\n",
        "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    if not args.disable_dp:\n",
        "        epsilon = privacy_engine.accountant.get_epsilon(delta=args.delta)\n",
        "        print(\n",
        "            f\"Train Epoch: {epoch} \\t\"\n",
        "            f\"Loss: {np.mean(losses):.6f} \"\n",
        "            f\"Accuracy: {correct/num_samples:.6f} \"\n",
        "            f\"(ε = {epsilon:.2f}, δ = {args.delta})\"\n",
        "        )\n",
        "    else:\n",
        "        # print(f\"Train Epoch: {epoch} \\t Loss: {np.mean(losses):.6f}\")\n",
        "        print(f\"Train Epoch: {epoch} \\t Loss: {np.mean(losses):.6f} \\t Accuracy: {correct/num_samples:.6f}\")\n",
        "\n",
        "    return correct/num_samples, np.mean(losses)"
      ],
      "metadata": {
        "id": "sevq4tKx8q1a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    num_samples = 0\n",
        "    for batch in test_loader:\n",
        "        num_samples += batch[0].shape[0]\n",
        "\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= num_samples\n",
        "\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            num_samples,\n",
        "            100.0 * correct / num_samples,\n",
        "        )\n",
        "    )\n",
        "    return correct / num_samples"
      ],
      "metadata": {
        "id": "QPIu_F1H84eC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples = 1000\n",
        "test_examples = 1000\n",
        "batch_size = 100\n",
        "\n",
        "mnist_train = MNIST(root=\"./data\", train=True, download=True,transform=transforms.Compose(\n",
        "                       [transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307), (0.3081)),]))\n",
        "mnist_test = MNIST(root=\"./data\", train=False, download=True,transform=transforms.Compose(\n",
        "                       [transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307), (0.3081)),]))\n",
        "\n",
        "# Create a subset sampler that selects num_examples randomly from the dataset\n",
        "indices_train = torch.randperm(len(mnist_train))[:train_examples]\n",
        "sampler_train = SubsetRandomSampler(indices_train)\n",
        "indices_test = torch.randperm(len(mnist_test))[:test_examples]\n",
        "sampler_test = SubsetRandomSampler(indices_test)\n",
        "\n",
        "train_loader = DataLoader(dataset=mnist_train, batch_size=batch_size, sampler=sampler_train)\n",
        "test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size, sampler=sampler_test)"
      ],
      "metadata": {
        "id": "_33p4_1i-2dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54082ca8-8053-4bb8-84c5-47b6375a5da9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 191983298.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 30729501.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 59841579.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 17904632.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping with DP engine"
      ],
      "metadata": {
        "id": "YyoyfdLAifZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from art.estimators.classification.pytorch import PyTorchClassifier\n",
        "\n",
        "run_results = []\n",
        "args.disable_dp=True # considering no DP\n",
        "for _ in range(args.n_runs):\n",
        "    model = SampleConvNet().to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0)\n",
        "    privacy_engine = None\n",
        "\n",
        "    if not args.disable_dp:\n",
        "        privacy_engine = PrivacyEngine(secure_mode=args.secure_rng)\n",
        "        model, optimizer, train_loader = privacy_engine.make_private(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=train_loader,\n",
        "            noise_multiplier=args.sigma,\n",
        "            max_grad_norm=args.max_per_sample_grad_norm,\n",
        "        )\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train(args, model, device, train_loader, optimizer, privacy_engine, epoch)\n",
        "    run_results.append(test(model, device, test_loader))\n",
        "\n",
        "if len(run_results) > 1:\n",
        "    print(\n",
        "        \"Accuracy averaged over {} runs: {:.2f}% ± {:.2f}%\".format(\n",
        "            len(run_results), np.mean(run_results) * 100, np.std(run_results) * 100\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xipL6vEJieSB",
        "outputId": "4988683c-62e5-4268-ed33-78ae014efaf3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \t Loss: 2.254601 \t Accuracy: 0.150000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 41.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \t Loss: 2.266713 \t Accuracy: 0.265000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \t Loss: 2.178314 \t Accuracy: 0.187000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 36.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \t Loss: 2.011638 \t Accuracy: 0.311000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 26.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \t Loss: 1.770436 \t Accuracy: 0.421000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 29.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \t Loss: 1.376453 \t Accuracy: 0.518000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 21.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \t Loss: 1.387051 \t Accuracy: 0.535000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 10.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \t Loss: 1.052293 \t Accuracy: 0.643000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 38.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \t Loss: 0.985843 \t Accuracy: 0.696000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \t Loss: 0.451853 \t Accuracy: 0.848000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 42.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \t Loss: 0.316122 \t Accuracy: 0.906000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \t Loss: 0.496036 \t Accuracy: 0.839000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 40.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \t Loss: 0.301631 \t Accuracy: 0.905000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 37.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \t Loss: 0.147573 \t Accuracy: 0.949000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 41.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \t Loss: 0.200132 \t Accuracy: 0.930000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 42.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0145, Accuracy: 701/1000 (70.10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model accuracy"
      ],
      "metadata": {
        "id": "XIkBNlc26Zcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "for batch in train_loader:\n",
        "    data, labels = batch\n",
        "    x_train.append(data.numpy())\n",
        "    y_train.append(labels.numpy())\n",
        "x_train = np.concatenate(x_train, axis=0)\n",
        "y_train = np.concatenate(y_train, axis=0)"
      ],
      "metadata": {
        "id": "H1PrsgyrmMYc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "for batch in test_loader:\n",
        "    data, labels = batch\n",
        "    x_test.append(data.numpy())\n",
        "    y_test.append(labels.numpy())\n",
        "x_test = np.concatenate(x_test, axis=0)\n",
        "y_test = np.concatenate(y_test, axis=0)"
      ],
      "metadata": {
        "id": "EkotmYdujMZ4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer_ori =  optim.SGD(model.parameters(), lr=args.lr, momentum=0)\n",
        "\n",
        "mlp_art_model = PyTorchClassifier(model=model, loss=criterion, optimizer=optimizer_ori, input_shape=(1, 28, 28), nb_classes=10)\n",
        "\n",
        "train_pred = np.array([np.argmax(arr) for arr in mlp_art_model.predict(x_train.astype(np.float32))])\n",
        "print('Base model Train accuracy: ', np.sum(train_pred == y_train) / len(y_train))\n",
        "\n",
        "test_pred = np.array([np.argmax(arr) for arr in mlp_art_model.predict(x_test.astype(np.float32))])\n",
        "print('Base model Test accuracy: ', np.sum(test_pred == y_test) / len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQSc1w7wQyIs",
        "outputId": "9dad4bdc-0e68-456e-fadc-08b695b739cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model Train accuracy:  0.74\n",
            "Base model Test accuracy:  0.701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Epsilon for DP"
      ],
      "metadata": {
        "id": "ShIENFoZTnGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_results = []\n",
        "for _ in range(args.n_runs):\n",
        "    model = SampleConvNet().to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0)\n",
        "    privacy_engine = None\n",
        "\n",
        "    if not args.disable_dp:\n",
        "        privacy_engine = PrivacyEngine(secure_mode=args.secure_rng)\n",
        "        model, optimizer, train_loader = privacy_engine.make_private(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=train_loader,\n",
        "            noise_multiplier=args.sigma,\n",
        "            max_grad_norm=args.max_per_sample_grad_norm,\n",
        "        )\n",
        "        model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "        module=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=train_loader,\n",
        "        epochs=args.epochs+1,\n",
        "        target_epsilon=args.epsilon,\n",
        "        target_delta=args.delta,\n",
        "        max_grad_norm=args.max_per_sample_grad_norm,\n",
        "    )\n",
        "\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train(args, model, device, train_loader, optimizer, privacy_engine, epoch)\n",
        "    run_results.append(test(model, device, test_loader))\n",
        "\n",
        "if len(run_results) > 1:\n",
        "    print(\n",
        "        \"Accuracy averaged over {} runs: {:.2f}% ± {:.2f}%\".format(\n",
        "            len(run_results), np.mean(run_results) * 100, np.std(run_results) * 100\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8YNbaldSOBM",
        "outputId": "9ded1725-a5ef-4ed6-dbb6-eeee61fccbd3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 25.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \t Loss: 2.214102 \t Accuracy: 0.168000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 38.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \t Loss: 2.109853 \t Accuracy: 0.289000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \t Loss: 2.160220 \t Accuracy: 0.242000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \t Loss: 1.996287 \t Accuracy: 0.340000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 41.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \t Loss: 2.183769 \t Accuracy: 0.249000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \t Loss: 1.663963 \t Accuracy: 0.423000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 40.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \t Loss: 2.016232 \t Accuracy: 0.408000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \t Loss: 2.142611 \t Accuracy: 0.272000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 39.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \t Loss: 2.239400 \t Accuracy: 0.240000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 41.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \t Loss: 2.317804 \t Accuracy: 0.142000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 40.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \t Loss: 2.242824 \t Accuracy: 0.240000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 28.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \t Loss: 1.994417 \t Accuracy: 0.311000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 29.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \t Loss: 1.570620 \t Accuracy: 0.458000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 26.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \t Loss: 1.411424 \t Accuracy: 0.519000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \t Loss: 1.060936 \t Accuracy: 0.630000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 24.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0096, Accuracy: 679/1000 (67.90%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with multiple dataset sizes"
      ],
      "metadata": {
        "id": "XRWUKi-HYy6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_and_test_loaders(train_examples,test_examples=50,batch_size=10):\n",
        "\n",
        "  batch_size = min(batch_size,train_examples)\n",
        "\n",
        "  mnist_train = MNIST(root=\"./data\", train=True, download=True,transform=transforms.Compose(\n",
        "                        [transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1307), (0.3081)),]))\n",
        "  mnist_test = MNIST(root=\"./data\", train=False, download=True,transform=transforms.Compose(\n",
        "                        [transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.1307), (0.3081)),]))\n",
        "\n",
        "  # Create a subset sampler that selects num_examples randomly from the dataset\n",
        "  indices_train = np.random.choice(len(mnist_train), train_examples, replace=False)\n",
        "  indices_test = np.random.choice(len(mnist_test), test_examples, replace=False)\n",
        "  train_set_small = torch.utils.data.Subset(mnist_train, indices_train)\n",
        "  test_set_small = torch.utils.data.Subset(mnist_test, indices_test)\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_set_small, batch_size=batch_size)\n",
        "  test_loader = DataLoader(dataset=mnist_test, batch_size=batch_size)\n",
        "  return train_loader,test_loader"
      ],
      "metadata": {
        "id": "qi4wOSYGYuSs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,test = get_train_and_test_loaders(100, 50,10)"
      ],
      "metadata": {
        "id": "YsD-ALVHr6tp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, train_loader, optimizer, privacy_engine, epoch):\n",
        "    # sample function to get length of the dataset\n",
        "    num_samples = 0\n",
        "    for batch in train_loader:\n",
        "        num_samples += batch[0].shape[0]\n",
        "\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "\n",
        "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    if not args.disable_dp:\n",
        "        epsilon = privacy_engine.accountant.get_epsilon(delta=args.delta)\n",
        "        print(\n",
        "            f\"Train Epoch: {epoch} \\t\"\n",
        "            f\"Loss: {np.mean(losses):.6f} \"\n",
        "            f\"Accuracy: {correct/num_samples:.6f} \"\n",
        "            f\"(ε = {epsilon:.2f}, δ = {args.delta})\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"Train Epoch: {epoch} \\t Loss: {np.mean(losses):.6f}\")\n",
        "        print(f\"Train Epoch: {epoch} \\t Loss: {np.mean(losses):.6f} \\t Accuracy: {correct/num_samples:.6f}\")\n",
        "\n",
        "    return correct/num_samples, np.mean(losses)"
      ],
      "metadata": {
        "id": "p7gD9J1mjLtk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysing the impact of different training set sizes"
      ],
      "metadata": {
        "id": "HRW10qt37D7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_exp(train_datset_len_list):\n",
        "  all_train_acc_list = []\n",
        "  all_test_acc_list = []\n",
        "  for data_len in train_dataset_len_list:\n",
        "    run_results = []\n",
        "    train_results = []\n",
        "    train_loader, test_loader = get_train_and_test_loaders(train_examples=data_len)\n",
        "    for _ in range(args.n_runs):\n",
        "        model = SampleConvNet().to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0)\n",
        "        privacy_engine = None\n",
        "\n",
        "        if not args.disable_dp:\n",
        "            privacy_engine = PrivacyEngine(secure_mode=args.secure_rng)\n",
        "            model, optimizer, train_loader = privacy_engine.make_private(\n",
        "                module=model,\n",
        "                optimizer=optimizer,\n",
        "                data_loader=train_loader,\n",
        "                noise_multiplier=args.sigma,\n",
        "                max_grad_norm=args.max_per_sample_grad_norm,\n",
        "            )\n",
        "            model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "            module=model,\n",
        "            optimizer=optimizer,\n",
        "            data_loader=train_loader,\n",
        "            epochs=args.epochs+1,\n",
        "            target_epsilon=args.epsilon,\n",
        "            target_delta=args.delta,\n",
        "            max_grad_norm=args.max_per_sample_grad_norm,\n",
        "        )\n",
        "\n",
        "\n",
        "        for epoch in range(1, args.epochs + 1):\n",
        "            train(args, model, device, train_loader, optimizer, privacy_engine, epoch)\n",
        "        test(model, device, test_loader)\n",
        "\n",
        "    all_train_acc_list.append(train_results)\n",
        "    all_test_acc_list.append(run_results)\n",
        "    if len(run_results) > 1:\n",
        "        print(\n",
        "            \"Accuracy averaged over {} runs: {:.2f}% ± {:.2f}% for dataset len{}\".format(\n",
        "                len(run_results), np.mean(run_results) * 100, np.std(run_results) * 100, data_len\n",
        "            )\n",
        "        )\n",
        "  return all_train_acc_list,all_test_acc_list"
      ],
      "metadata": {
        "id": "Q90ravj3Vb2V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    num_samples = 0\n",
        "    for batch in test_loader:\n",
        "        num_samples += batch[0].shape[0]\n",
        "\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(\n",
        "                dim=1, keepdim=True\n",
        "            )  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= num_samples\n",
        "\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
        "            test_loss,\n",
        "            correct,\n",
        "            num_samples,\n",
        "            100.0 * correct / num_samples,\n",
        "        )\n",
        "    )\n",
        "    return correct / num_samples"
      ],
      "metadata": {
        "id": "5YoMp22Atvrv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_len_list = [15]\n",
        "args.epsilon=1\n",
        "\n",
        "all_train_acc_list_2,all_test_acc_list_2=run_exp(train_dataset_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzJdZKYThlUI",
        "outputId": "2bf5e8c9-3e8b-42b2-bbbf-4c6dee79b548"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 60.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \t Loss: 2.309582\n",
            "Train Epoch: 1 \t Loss: 2.309582 \t Accuracy: 0.200000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 187.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \t Loss: 2.417897\n",
            "Train Epoch: 2 \t Loss: 2.417897 \t Accuracy: 0.066667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 192.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \t Loss: 2.214867\n",
            "Train Epoch: 3 \t Loss: 2.214867 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 180.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \t Loss: 2.107810\n",
            "Train Epoch: 4 \t Loss: 2.107810 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 207.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \t Loss: 2.287778\n",
            "Train Epoch: 5 \t Loss: 2.287778 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 147.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \t Loss: 2.104883\n",
            "Train Epoch: 6 \t Loss: 2.104883 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 211.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \t Loss: 2.011498\n",
            "Train Epoch: 7 \t Loss: 2.011498 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 221.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \t Loss: 1.992559\n",
            "Train Epoch: 8 \t Loss: 1.992559 \t Accuracy: 0.333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 199.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \t Loss: 1.839902\n",
            "Train Epoch: 9 \t Loss: 1.839902 \t Accuracy: 0.466667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 160.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \t Loss: 1.984872\n",
            "Train Epoch: 10 \t Loss: 1.984872 \t Accuracy: 0.200000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 212.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \t Loss: 3.227137\n",
            "Train Epoch: 11 \t Loss: 3.227137 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 172.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \t Loss: 2.026899\n",
            "Train Epoch: 12 \t Loss: 2.026899 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 201.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \t Loss: 2.000735\n",
            "Train Epoch: 13 \t Loss: 2.000735 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 145.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \t Loss: 1.973847\n",
            "Train Epoch: 14 \t Loss: 1.973847 \t Accuracy: 0.266667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 248.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \t Loss: 2.026254\n",
            "Train Epoch: 15 \t Loss: 2.026254 \t Accuracy: 0.066667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 325.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.2608, Accuracy: 982/10000 (9.82%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_len_list = [20]\n",
        "args.epsilon=1\n",
        "\n",
        "all_train_acc_list_3,all_test_acc_list_3=run_exp(train_dataset_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M28O44Mlo1_O",
        "outputId": "4960bd44-8d18-40fa-fce4-4ab8175c2afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "  z = np.log((np.exp(t) + q - 1) / q)\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "100%|██████████| 2/2 [00:13<00:00,  6.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \tLoss: 2.301947 Accuracy: 0.150852 (ε = 0.24, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \tLoss: 2.281597 Accuracy: 0.184027 (ε = 0.33, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:14<00:00,  7.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \tLoss: 2.267022 Accuracy: 0.190541 (ε = 0.41, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \tLoss: 2.250263 Accuracy: 0.204587 (ε = 0.48, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \tLoss: 2.228420 Accuracy: 0.239636 (ε = 0.54, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \tLoss: 2.202221 Accuracy: 0.273885 (ε = 0.59, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \tLoss: 2.174248 Accuracy: 0.319764 (ε = 0.64, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \tLoss: 2.139161 Accuracy: 0.366143 (ε = 0.69, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \tLoss: 2.101094 Accuracy: 0.417632 (ε = 0.73, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \tLoss: 2.056522 Accuracy: 0.475120 (ε = 0.77, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \tLoss: 2.007163 Accuracy: 0.526022 (ε = 0.81, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \tLoss: 1.949418 Accuracy: 0.556319 (ε = 0.85, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \tLoss: 1.890165 Accuracy: 0.575673 (ε = 0.89, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \tLoss: 1.824483 Accuracy: 0.596564 (ε = 0.93, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:13<00:00,  6.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \tLoss: 1.754239 Accuracy: 0.612885 (ε = 0.96, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 210.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1641, Accuracy: 36/50 (72.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_len_list = [50]\n",
        "args.epsilon=1\n",
        "\n",
        "all_train_acc_list_2,all_test_acc_list_2=run_exp(train_dataset_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp0LgveCphNr",
        "outputId": "2684a076-9b3e-473b-eb87-d4fe21653a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \tLoss: 2.292116 Accuracy: 0.122305 (ε = 0.24, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \tLoss: 2.253253 Accuracy: 0.283089 (ε = 0.34, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \tLoss: 2.200062 Accuracy: 0.383825 (ε = 0.42, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \tLoss: 2.122373 Accuracy: 0.440471 (ε = 0.48, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \tLoss: 2.015947 Accuracy: 0.502332 (ε = 0.54, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \tLoss: 1.883699 Accuracy: 0.569114 (ε = 0.59, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \tLoss: 1.729935 Accuracy: 0.620103 (ε = 0.64, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \tLoss: 1.571868 Accuracy: 0.651221 (ε = 0.69, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \tLoss: 1.427665 Accuracy: 0.668236 (ε = 0.73, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \tLoss: 1.299498 Accuracy: 0.681268 (ε = 0.78, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \tLoss: 1.177027 Accuracy: 0.698400 (ε = 0.82, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \tLoss: 1.074722 Accuracy: 0.709280 (ε = 0.85, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \tLoss: 0.987045 Accuracy: 0.726156 (ε = 0.89, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:14<00:00,  2.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \tLoss: 0.917207 Accuracy: 0.740609 (ε = 0.93, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:13<00:00,  2.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \tLoss: 0.850944 Accuracy: 0.754029 (ε = 0.96, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 154.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0734, Accuracy: 37/50 (74.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_len_list = [100]\n",
        "args.epsilon=1\n",
        "\n",
        "all_train_acc_list_2,all_test_acc_list_2=run_exp(train_dataset_len_list)"
      ],
      "metadata": {
        "id": "hSfuvS5DscXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f79763a-963b-4f71-cb57-d01e839a6a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 \tLoss: 2.261874 Accuracy: 0.160532 (ε = 0.24, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 \tLoss: 2.124238 Accuracy: 0.381287 (ε = 0.34, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 \tLoss: 1.865757 Accuracy: 0.550481 (ε = 0.42, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 4 \tLoss: 1.517238 Accuracy: 0.652262 (ε = 0.48, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 5 \tLoss: 1.190064 Accuracy: 0.689509 (ε = 0.54, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 6 \tLoss: 0.952285 Accuracy: 0.723820 (ε = 0.59, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 7 \tLoss: 0.795117 Accuracy: 0.748113 (ε = 0.64, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 8 \tLoss: 0.692150 Accuracy: 0.772774 (ε = 0.69, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 9 \tLoss: 0.639660 Accuracy: 0.787730 (ε = 0.73, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 10 \tLoss: 0.599429 Accuracy: 0.796043 (ε = 0.78, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 11 \tLoss: 0.561775 Accuracy: 0.823417 (ε = 0.81, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 12 \tLoss: 0.512282 Accuracy: 0.841506 (ε = 0.85, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 13 \tLoss: 0.473563 Accuracy: 0.848584 (ε = 0.89, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 14 \tLoss: 0.468459 Accuracy: 0.861254 (ε = 0.93, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:14<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 15 \tLoss: 0.452052 Accuracy: 0.854296 (ε = 0.96, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 222.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0374, Accuracy: 42/50 (84.00%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feUL7c0zmu2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}